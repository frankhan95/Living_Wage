{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping US Hourly Wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import lxml\n",
    "from lxml import html\n",
    "import cssselect\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Setting Up Methods and Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A helper method to get the document of a website. Requires an URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeSite(url):\n",
    "    #request and connect to the site\n",
    "    req = urllib2.Request(url, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "    con = urllib2.urlopen( req )\n",
    "\n",
    "    #read the connection as a document\n",
    "    doc_text = con.read()\n",
    "    doc = lxml.html.fromstring(doc_text)\n",
    "    doc.make_links_absolute(url)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A helper method that traverses through a county's website document and stores values for hourly wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCounties(doc, state):\n",
    "    #css paths to the website table\n",
    "    county_css = '.counties div a'\n",
    "    table_css = '.table-responsive'\n",
    "    \n",
    "    #for each county in the state\n",
    "    for b in doc.cssselect(county_css):\n",
    "        #populate lists for the dataframe\n",
    "        state_names.append(state)\n",
    "        county_name = b.text_content().strip()\n",
    "        county_names.append(county_name)\n",
    "        \n",
    "        #reference to the website table    \n",
    "        county_url = b.get('href')\n",
    "        county_doc = scrapeSite(county_url)\n",
    "        table = county_doc.cssselect(table_css)[0]\n",
    "        col_heads = table.cssselect('thead tr')[0]\n",
    "        \n",
    "        #Loops through the rows for the 3-types of hourly wages\n",
    "        wage_count = 0\n",
    "        for row in table.cssselect('tbody tr'):\n",
    "            col_head = col_heads.cssselect('th')[0].text_content().strip()\n",
    "            row_head = row.cssselect('td')[1].text_content().strip()\n",
    "            wage = row.cssselect('td')[1].text_content().strip()\n",
    "            hourly_wages[wage_count].append( float(wage[1:]))\n",
    "            wage_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize multiple lists that will be used to create a Pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepping data for Pandas DataFrame\n",
    "living_wages = []\n",
    "poverty_wages = []\n",
    "min_wages = []\n",
    "hourly_wages = [living_wages, poverty_wages, min_wages]\n",
    "county_names = []\n",
    "state_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Executing Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama\n",
      "Alaska\n",
      "Arizona\n",
      "Arkansas\n",
      "California\n",
      "Colorado\n",
      "Connecticut\n",
      "Delaware\n",
      "District of Columbia\n",
      "Florida\n",
      "Georgia\n",
      "Hawaii\n",
      "Idaho\n",
      "Illinois\n",
      "Indiana\n",
      "Iowa\n",
      "Kansas\n",
      "Kentucky\n",
      "Louisiana\n",
      "Maine\n",
      "Maryland\n",
      "Massachusetts\n",
      "Michigan\n",
      "Minnesota\n",
      "Mississippi\n",
      "Missouri\n",
      "Montana\n",
      "Nebraska\n",
      "Nevada\n",
      "New Hampshire\n",
      "New Jersey\n",
      "New Mexico\n",
      "New York\n",
      "North Carolina\n",
      "North Dakota\n",
      "Ohio\n",
      "Oklahoma\n",
      "Oregon\n",
      "Pennsylvania\n",
      "Rhode Island\n",
      "South Carolina\n",
      "South Dakota\n",
      "Tennessee\n",
      "Texas\n",
      "Utah\n",
      "Vermont\n",
      "Virginia\n",
      "Washington\n",
      "West Virginia\n",
      "Wisconsin\n",
      "Wyoming\n"
     ]
    }
   ],
   "source": [
    "state_css = \".states li a\"\n",
    "main_page = scrapeSite(\"http://livingwage.mit.edu\")\n",
    "state_names = []\n",
    "for state in main_page.cssselect(state_css):\n",
    "    \n",
    "    #get the name of the state and start another scrape\n",
    "    state_name = state.text_content()\n",
    "    state_url = state.get('href')\n",
    "    county_doc = scrapeSite(state_url)\n",
    "    getCounties(county_doc, state_name)\n",
    "    \n",
    "    #show which state is finished being scraped\n",
    "    print state_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Saving Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>living</th>\n",
       "      <th>min</th>\n",
       "      <th>poverty</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga County</td>\n",
       "      <td>11.10</td>\n",
       "      <td>7.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>12.55</td>\n",
       "      <td>7.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbour County</td>\n",
       "      <td>10.54</td>\n",
       "      <td>7.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibb County</td>\n",
       "      <td>11.62</td>\n",
       "      <td>7.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blount County</td>\n",
       "      <td>11.62</td>\n",
       "      <td>7.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           county  living   min  poverty    state\n",
       "0  Autauga County   11.10  7.25      5.0  Alabama\n",
       "1  Baldwin County   12.55  7.25      5.0  Alabama\n",
       "2  Barbour County   10.54  7.25      5.0  Alabama\n",
       "3     Bibb County   11.62  7.25      5.0  Alabama\n",
       "4   Blount County   11.62  7.25      5.0  Alabama"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#construct a Pandas DataFrame using the lists created above\n",
    "data = {'state': state_names,\n",
    "        'county': county_names,\n",
    "        'living': living_wages,\n",
    "        'poverty': poverty_wages,\n",
    "        'min': min_wages}\n",
    "\n",
    "pandas_df = pandas.DataFrame(data) \n",
    "pandas_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pandas dataframe to a csv file\n",
    "pandas_df.to_csv('USA_Wages.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
